{
	"nodes":[
		{"id":"a1b2c3d4e5f60001","type":"group","text":"EXAM MAP - Midterm 2026/02/24","x":-400,"y":-600,"width":2400,"height":380,"color":"1"},
		{"id":"a1b2c3d4e5f60002","type":"text","text":"# CSCI 6751 Midterm Review\n## 期中复习知识导图\n\n**考试日期：2026年2月24日**\n**范围：Week01 ~ Week05（全部5周内容）**\n**总分：100分**","x":-380,"y":-580,"width":400,"height":180,"color":"6"},
		{"id":"a1b2c3d4e5f60003","type":"text","text":"## Q1: Gradient Descent (25pts)\n**计算题 - 每年必考！**\n\n- Multivariate GD + L2 Regularization\n- 6步手算：predict -> error -> grad_a -> grad_b -> update_a -> update_b\n- Update: theta_new = theta_old - eta * gradient\n- L2 gradient adds: +2*lambda*theta_j\n\n**来源：Week03 + Week04**","x":60,"y":-580,"width":420,"height":310,"color":"1"},
		{"id":"a1b2c3d4e5f60004","type":"text","text":"## Q2: Fuzzy Logic (25pts)\n**计算题 - 每年必考！**\n\n- Trapezoidal membership function\n- Multi-input fuzzy inference\n- Firing Strength: AND=MIN, OR=MAX\n- Centroid Defuzzification:\n  Output = SUM(FS * Output) / SUM(FS)\n\n**来源：Week01 Fuzzy Logic**","x":520,"y":-580,"width":420,"height":310,"color":"1"},
		{"id":"a1b2c3d4e5f60005","type":"text","text":"## MCQ: 50pts (10 questions)\n**选择题考点：**\n\n1. GD vs Normal Equation (何时用哪个)\n2. L1 vs L2 Regularization (关键区别)\n3. Matrix dimensions (矩阵维度)\n4. Overfitting vs Underfitting (判断标准)\n5. Evaluation Metrics (MAE/MSE/RMSE/R2)\n6. Precision vs Recall (何时优先哪个)\n7. Supervised vs Unsupervised (区分)\n8. Regression vs Classification (看输出)\n9. Fuzzy vs Classical Logic (区别)\n10. Cross-Validation (目的与方法)\n\n**来源：Week01 ~ Week05 全覆盖**","x":980,"y":-580,"width":400,"height":340,"color":"1"},

		{"id":"a1b2c3d4e5f61000","type":"group","text":"Week 01: AI Introduction","x":-2200,"y":-100,"width":680,"height":1150,"color":"4"},
		{"id":"a1b2c3d4e5f61001","type":"text","text":"## Week 01\n**Introduction to AI**","x":-2180,"y":-80,"width":300,"height":80,"color":"4"},
		{"id":"a1b2c3d4e5f61002","type":"text","text":"### AI Definition (AI 定义)\n**5 core capabilities:**\n1. **Learning** (学习)\n2. **Reasoning** (推理)\n3. **Problem Solving** (解决问题)\n4. **Perception** (感知)\n5. **Language Understanding** (语言理解)","x":-2180,"y":30,"width":300,"height":230,"color":"4"},
		{"id":"a1b2c3d4e5f61003","type":"text","text":"### Turing Test (1950)\n- Alan Turing 提出\n- 机器能否展示与人类无法区分的智能行为？\n- Imitation Game: 人类评判者通过文字与机器/人交流\n- 至今仍是AI的重要基准","x":-2180,"y":290,"width":300,"height":200,"color":"4"},
		{"id":"a1b2c3d4e5f61004","type":"text","text":"### AI History (AI 历史三次浪潮)\n**Boom 1 (1950s):**\n- 1950 Turing Test\n- 1956 Dartmouth Conference (AI诞生)\n\n**Boom 2 (1980s) - Expert Systems:**\n- Rule-based reasoning\n- MYCIN, DENDRAL\n\n**Boom 3 (2010s) - Deep Learning:**\n- 2012 AlexNet / ImageNet\n- 2020+ GPT-3/4, ChatGPT","x":-2180,"y":520,"width":300,"height":340,"color":"4"},
		{"id":"a1b2c3d4e5f61005","type":"text","text":"### Expert Systems (专家系统)\n**组成：**\n- Knowledge Base (知识库 - IF-THEN rules)\n- Inference Engine (推理引擎)\n\n**特点：**\n- 基于人类专家知识\n- 无学习能力 (no learning!)\n- 例：MYCIN 医疗诊断\n\n**MCQ考点：Expert System vs ML**","x":-1840,"y":30,"width":300,"height":300,"color":"4"},
		{"id":"a1b2c3d4e5f61006","type":"text","text":"### Neural Networks (神经网络基础)\n**结构：**\nInput Layer -> Hidden Layer(s) -> Output Layer\n\n**受生物神经元启发**\n- Weights (权重)\n- Bias (偏置)\n- Activation Function\n\n**关键人物：**\nGeoffrey Hinton, Yann LeCun","x":-1840,"y":370,"width":300,"height":280,"color":"4"},

		{"id":"a1b2c3d4e5f62000","type":"group","text":"Week 01: Fuzzy Logic (EXAM CRITICAL - 25pts!)","x":-2200,"y":1150,"width":1100,"height":1050,"color":"1"},
		{"id":"a1b2c3d4e5f62001","type":"text","text":"## Fuzzy Logic (模糊逻辑)\n**每年必考25分计算题！**\n\n**Classical Logic vs Fuzzy Logic:**\n- Classical: binary (0 or 1) - 是或否\n- Fuzzy: degree [0, 1] - 程度\n  - e.g., 0.7 = \"quite tall\"\n\n**核心思想：**\n用隶属度(membership degree)描述\n\"在多大程度上属于某个类别\"","x":-2180,"y":1170,"width":380,"height":300,"color":"1"},
		{"id":"a1b2c3d4e5f62002","type":"text","text":"### Triangular MF: trimf(a, b, c)\n**三角形隶属函数：**\n\n- x <= a: mu = 0\n- a < x <= b: mu = (x - a) / (b - a)\n- b < x < c: mu = (c - x) / (c - b)\n- x >= c: mu = 0\n\n**图形：** 三角形，顶点在 b 处 mu=1\n\n例：trimf(20, 30, 40)\nx=25 -> mu = (25-20)/(30-20) = 0.5","x":-2180,"y":1500,"width":340,"height":310,"color":"3"},
		{"id":"a1b2c3d4e5f62003","type":"text","text":"### Trapezoidal MF: trapmf(a, b, c, d)\n**梯形隶属函数（考试常用）：**\n\n- x <= a: mu = 0\n- a < x < b: mu = (x - a) / (b - a)\n- b <= x <= c: mu = 1 (plateau)\n- c < x < d: mu = (d - x) / (d - c)\n- x >= d: mu = 0\n\n**图形：** 梯形，b到c之间 mu=1\n\n例：trapmf(10, 20, 30, 40)\nx=15 -> mu = (15-10)/(20-10) = 0.5\nx=25 -> mu = 1.0 (on plateau)","x":-1800,"y":1500,"width":340,"height":370,"color":"3"},
		{"id":"a1b2c3d4e5f62004","type":"text","text":"### Fuzzy Inference System (4 Steps)\n**模糊推理系统（完整流程）：**\n\n**Step 1: Fuzzification (模糊化)**\n- 将crisp input -> membership degrees\n- 用membership function计算\n\n**Step 2: Rule Evaluation (规则评估)**\n- IF x IS A AND y IS B THEN z IS C\n- Firing Strength: AND = MIN, OR = MAX\n\n**Step 3: Aggregation (聚合)**\n- 合并所有规则的输出\n\n**Step 4: Defuzzification (去模糊化)**\n- Centroid method:\n  Output = SUM(FS_i * Center_i) / SUM(FS_i)\n\n**计算题典型流程：**\n给定input values -> 查表算mu ->\n对每条规则取MIN -> 加权平均得output","x":-1420,"y":1170,"width":300,"height":580,"color":"1"},
		{"id":"a1b2c3d4e5f62005","type":"text","text":"### Fuzzy 计算示例要点\n\n**Firing Strength 计算：**\n- Rule: IF x=A AND y=B\n- FS = MIN(mu_A(x), mu_B(y))\n\n**Centroid Defuzzification：**\n- Output = (FS1*O1 + FS2*O2) / (FS1+FS2)\n\n**常见错误：**\n- AND用MIN，不是乘法！\n- OR用MAX，不是加法！\n- trapmf的plateau区间mu=1\n- 别忘了FS=0的规则不影响output","x":-1420,"y":1780,"width":300,"height":340,"color":"1"},

		{"id":"a1b2c3d4e5f63000","type":"group","text":"Week 02: Machine Learning Fundamentals","x":-1040,"y":-100,"width":680,"height":1150,"color":"5"},
		{"id":"a1b2c3d4e5f63001","type":"text","text":"## Week 02\n**Machine Learning Fundamentals**","x":-1020,"y":-80,"width":300,"height":80,"color":"5"},
		{"id":"a1b2c3d4e5f63002","type":"text","text":"### ML Definition (T-P-E Framework)\n**Tom Mitchell (1997):**\n\"A program learns from Experience (E)\nwith respect to Task (T)\nand Performance measure (P),\nif P on T improves with E.\"\n\n- **T**: 任务 (e.g., classify email)\n- **P**: 性能度量 (e.g., accuracy)\n- **E**: 经验/数据 (e.g., labeled emails)\n\n**MCQ考点：识别T/P/E**","x":-1020,"y":30,"width":300,"height":320,"color":"5"},
		{"id":"a1b2c3d4e5f63003","type":"text","text":"### Supervised Learning (监督学习)\n**有标签数据 (labeled data)**\n\n**Regression (回归):** 输出连续值\n- 房价预测: $350,000\n- 住院天数: 4.6 days\n\n**Classification (分类):** 输出离散类别\n- 邮件分类: spam/not-spam\n- 疾病诊断: Type 1/2/3\n\n**MCQ考点：看输出类型判断！**\n- 连续数值 -> Regression\n- 离散类别 -> Classification","x":-1020,"y":380,"width":300,"height":370,"color":"5"},
		{"id":"a1b2c3d4e5f63004","type":"text","text":"### Unsupervised Learning (无监督学习)\n**无标签数据 (no labels)**\n\n**Clustering (聚类):** 自动分组\n- K-Means, DBSCAN\n- 例：客户细分\n\n**Dimensionality Reduction (降维):**\n- PCA\n- 例：数据可视化","x":-680,"y":30,"width":300,"height":280,"color":"5"},
		{"id":"a1b2c3d4e5f63005","type":"text","text":"### Reinforcement Learning (强化学习)\n**Trial & Error + Reward/Penalty**\n\n**Components:**\n- Agent (智能体)\n- Environment (环境)\n- States (状态)\n- Actions (动作)\n- Rewards (奖励)\n\n**例：** AlphaGo, 机器人导航, 游戏AI","x":-680,"y":340,"width":300,"height":280,"color":"5"},
		{"id":"a1b2c3d4e5f63006","type":"text","text":"### Data Encoding (数据编码)\n**Categorical -> Numeric**\n\n**One-Hot Encoding:**\n- K categories -> K binary columns\n- Red: [1,0,0], Green: [0,1,0]\n- 用于：Tree-based models\n\n**Dummy Encoding:**\n- K categories -> K-1 columns\n- 去掉一个参考类别\n- 用于：Linear models\n  (避免 multicollinearity)\n\n**MCQ考点：One-Hot vs Dummy**\n- One-Hot: K columns\n- Dummy: K-1 columns","x":-680,"y":650,"width":300,"height":400,"color":"5"},

		{"id":"a1b2c3d4e5f64000","type":"group","text":"Week 03: Linear Regression (EXAM CRITICAL)","x":-300,"y":-100,"width":1100,"height":1350,"color":"1"},
		{"id":"a1b2c3d4e5f64001","type":"text","text":"## Week 03\n**Linear Regression (线性回归)**","x":-280,"y":-80,"width":300,"height":80,"color":"2"},
		{"id":"a1b2c3d4e5f64002","type":"text","text":"### Linear Regression Models\n**Simple Linear Regression:**\ny = ax + b\n(1 feature, 2 parameters)\n\n**Multiple Linear Regression:**\ny = theta_0 + theta_1*x1 + theta_2*x2 + ...\n(n features, n+1 parameters)\n\n**Matrix form:**\ny = X * theta\nwhere X includes column of 1s for bias","x":-280,"y":30,"width":320,"height":280,"color":"2"},
		{"id":"a1b2c3d4e5f64003","type":"text","text":"### Normal Equation (闭式解)\n**MUST MEMORIZE:**\ntheta = (X^T * X)^(-1) * X^T * y\n\n**Hand Calculation Steps:**\n1. Build X matrix (add 1s column)\n2. Compute X^T (transpose)\n3. Compute X^T * X\n4. Compute (X^T * X)^(-1)\n5. Compute X^T * y\n6. Multiply: (X^T*X)^(-1) * X^T*y\n\n**2x2 Matrix Inverse:**\n[a b; c d]^(-1) = (1/det) * [d -b; -c a]\nwhere det = a*d - b*c\n\n**Pros:** One-shot, exact solution\n**Cons:** Slow for large n (O(n^3))","x":-280,"y":340,"width":320,"height":440,"color":"3"},
		{"id":"a1b2c3d4e5f64004","type":"text","text":"### Gradient Descent (梯度下降)\n**EXAM CRITICAL - 25pts!**\n\n**Update Rule:**\ntheta_new = theta_old - eta * gradient\n\n**For y = a*x + b:**\n- dJ/da = (2/n) * SUM((y_hat - y) * x)\n- dJ/db = (2/n) * SUM(y_hat - y)\n\n**6-Step Hand Calculation:**\n1. Predict: y_hat = a*x + b\n2. Error: e = y_hat - y\n3. Gradient_a: (2/n)*SUM(e * x)\n4. Gradient_b: (2/n)*SUM(e)\n5. Update_a: a_new = a - eta * grad_a\n6. Update_b: b_new = b - eta * grad_b\n\n**Multivariate Gradient:**\ndJ/d(theta_j) = (2/n) * SUM((y_hat_i - y_i) * x_ji)","x":80,"y":30,"width":360,"height":530,"color":"1"},
		{"id":"a1b2c3d4e5f64005","type":"text","text":"### GD vs Normal Equation\n**MCQ常考对比：**\n\n| | GD | Normal Eq |\n|---|---|---|\n| 方法 | Iterative | Closed-form |\n| Learning Rate | 需要 | 不需要 |\n| 大数据 | 适合 | 慢(O(n^3)) |\n| 特征多 | OK | 需求逆 |\n| 收敛 | 需调参 | 精确解 |\n\n**何时用GD？**\n- n > 10,000 features\n- 数据量很大\n\n**何时用Normal Eq？**\n- n < 10,000 features\n- 想要精确解","x":80,"y":590,"width":360,"height":380,"color":"2"},
		{"id":"a1b2c3d4e5f64006","type":"text","text":"### Learning Rate (eta)\n\n**eta too large:**\n-> Overshoot, diverge (发散)\n-> 不能收敛到最小值\n\n**eta too small:**\n-> Very slow convergence\n-> 需要太多迭代\n\n**Optimal eta:**\n-> 平衡速度与稳定性\n\n**eta is a Hyperparameter**\n- 不从数据中学习\n- 需要人为设定/调参","x":480,"y":30,"width":280,"height":340,"color":"3"},
		{"id":"a1b2c3d4e5f64007","type":"text","text":"### Matrix Dimensions (MCQ考点)\n\n**X:** (m x (n+1)) - m samples, n features +1\n**theta:** ((n+1) x 1) - n+1 parameters\n**y:** (m x 1) - m target values\n**X^T:** ((n+1) x m)\n**X^T*X:** ((n+1) x (n+1))\n**(X^T*X)^(-1):** ((n+1) x (n+1))\n**X^T*y:** ((n+1) x 1)\n**theta:** ((n+1) x 1) - final result\n\n**检查：** 结果theta维度应为(n+1) x 1","x":480,"y":400,"width":280,"height":340,"color":"3"},

		{"id":"a1b2c3d4e5f65000","type":"group","text":"Week 04: Overfitting & Regularization","x":860,"y":-100,"width":720,"height":1350,"color":"2"},
		{"id":"a1b2c3d4e5f65001","type":"text","text":"## Week 04\n**Overfitting & Regularization**","x":880,"y":-80,"width":300,"height":80,"color":"2"},
		{"id":"a1b2c3d4e5f65002","type":"text","text":"### Underfitting (欠拟合)\n**Model too simple**\n\n- Train Error: HIGH\n- Test Error: HIGH\n- 模型太简单，没有捕捉到数据模式\n\n**原因：**\n- Polynomial degree too low\n- Too few features\n- Lambda too large\n\n**解决：**\n- 增加模型复杂度\n- 增加特征\n- 减小 lambda","x":880,"y":30,"width":320,"height":340,"color":"2"},
		{"id":"a1b2c3d4e5f65003","type":"text","text":"### Overfitting (过拟合)\n**Model too complex**\n\n- Train Error: VERY LOW\n- Test Error: HIGH\n- 模型记住了噪声而非模式\n\n**原因：**\n- Polynomial degree too high\n- Too many parameters\n- Lambda too small or 0\n\n**解决：**\n- Regularization (L1/L2)\n- More training data\n- Reduce model complexity\n- 增大 lambda","x":880,"y":400,"width":320,"height":370,"color":"2"},
		{"id":"a1b2c3d4e5f65004","type":"text","text":"### Good Fit (良好拟合)\n**Just right!**\n\n- Train Error: LOW\n- Test Error: LOW\n- Generalizes well to unseen data","x":880,"y":800,"width":320,"height":150,"color":"4"},
		{"id":"a1b2c3d4e5f65005","type":"text","text":"### L2 Regularization (Ridge)\n**J = MSE + lambda * SUM(theta_j^2)**\n\n**Gradient with L2:**\ndJ/d(theta_j) = original_grad + 2*lambda*theta_j\n\n**效果：**\n- Shrinks coefficients toward 0\n- But never exactly 0\n- All features retained\n\n**考试计算：**\nGD + L2 = standard GD step\n+ add 2*lambda*theta_j to gradient","x":1240,"y":30,"width":320,"height":340,"color":"1"},
		{"id":"a1b2c3d4e5f65006","type":"text","text":"### L1 Regularization (Lasso)\n**J = MSE + lambda * SUM(|theta_j|)**\n\n**效果：**\n- Makes some coefficients exactly 0\n- Automatic feature selection!\n- Sparse model\n\n**L1 vs L2 (MCQ必考)：**\n| | L1 (Lasso) | L2 (Ridge) |\n|---|---|---|\n| 惩罚 | abs(theta) | theta^2 |\n| 系数 | Can = 0 | Near 0 |\n| 特征选择 | YES | NO |\n| 稀疏 | YES | NO |","x":1240,"y":400,"width":320,"height":370,"color":"2"},
		{"id":"a1b2c3d4e5f65007","type":"text","text":"### Lambda (lambda) Effect\n\n**lambda = 0:**\n-> No regularization\n-> May overfit\n\n**lambda too small:**\n-> Weak regularization\n-> Still may overfit\n\n**lambda too large:**\n-> Too much penalty\n-> May underfit (all coefficients -> 0)\n\n**lambda is a Hyperparameter**\n- Tuned via Cross-Validation\n- Grid Search: try many values","x":1240,"y":800,"width":320,"height":350,"color":"3"},

		{"id":"a1b2c3d4e5f66000","type":"group","text":"Week 05: Model Evaluation Metrics (NEW!)","x":1640,"y":-100,"width":760,"height":1350,"color":"5"},
		{"id":"a1b2c3d4e5f66001","type":"text","text":"## Week 05\n**Model Evaluation Metrics**","x":1660,"y":-80,"width":300,"height":80,"color":"5"},
		{"id":"a1b2c3d4e5f66002","type":"text","text":"### Validation Set vs Test Set\n\n**Validation Set:**\n- Split from training data\n- Used for hyperparameter tuning\n- Can be used repeatedly\n\n**Test Set:**\n- Completely independent\n- Used ONLY for final evaluation\n- Never used during training/tuning\n\n**Typical Split:**\nTrain: 60% | Validation: 20% | Test: 20%","x":1660,"y":30,"width":340,"height":320,"color":"5"},
		{"id":"a1b2c3d4e5f66003","type":"text","text":"### Regression Metrics\n\n**MAE (Mean Absolute Error):**\nMAE = (1/n) * SUM(|y - y_hat|)\n- Same unit as y\n- Robust to outliers\n\n**MSE (Mean Squared Error):**\nMSE = (1/n) * SUM((y - y_hat)^2)\n- Squared unit (e.g., dollars^2)\n- Penalizes large errors more\n\n**RMSE (Root Mean Squared Error):**\nRMSE = sqrt(MSE)\n- Same unit as y\n- Most commonly used\n\n**R-squared (R^2):**\nR^2 = 1 - SS_res / SS_tot\n- Range: (-inf, 1]\n- R^2 = 1: perfect fit\n- R^2 = 0: same as mean prediction\n- R^2 < 0: worse than mean","x":1660,"y":380,"width":340,"height":530,"color":"3"},
		{"id":"a1b2c3d4e5f66004","type":"text","text":"### Classification Metrics\n\n**Confusion Matrix:**\n|  | Predicted + | Predicted - |\n|---|---|---|\n| Actual + | TP | FN |\n| Actual - | FP | TN |\n\n**Precision = TP / (TP + FP)**\n\"Of all predicted positive, how many correct?\"\n\n**Recall = TP / (TP + FN)**\n\"Of all actual positive, how many found?\"\n\n**F1 = 2 * P * R / (P + R)**\nHarmonic mean of Precision & Recall\n\n**Accuracy = (TP+TN) / (TP+FP+FN+TN)**","x":2040,"y":30,"width":340,"height":450,"color":"3"},
		{"id":"a1b2c3d4e5f66005","type":"text","text":"### Type I & Type II Errors\n\n**Type I Error = False Positive (FP)**\n\"False alarm\" - 说有其实没有\n例：健康人被诊断为有病\n\n**Type II Error = False Negative (FN)**\n\"Missed detection\" - 说没有其实有\n例：病人被诊断为健康\n\n**场景选择 (MCQ考点!)：**\n- Medical diagnosis -> Recall优先\n  (不能漏诊，FN代价太高)\n- Spam filter -> Precision优先\n  (不能误判正常邮件，FP代价高)","x":2040,"y":510,"width":340,"height":380,"color":"2"},
		{"id":"a1b2c3d4e5f66006","type":"text","text":"### K-Fold Cross-Validation\n\n**Method:**\n1. Split data into K folds\n2. Train on K-1 folds, validate on 1\n3. Repeat K times (each fold as validation)\n4. Average the K results\n\n**Typical K = 5 or 10**\n\n**Advantages:**\n- Every data point used for validation\n- More reliable estimate\n- Reduces variance of estimate\n\n**Used for:**\n- Model selection\n- Hyperparameter tuning\n- Performance estimation","x":2040,"y":920,"width":340,"height":380,"color":"5"},

		{"id":"a1b2c3d4e5f67000","type":"group","text":"Hyperparameters Summary","x":-300,"y":1350,"width":500,"height":300,"color":"3"},
		{"id":"a1b2c3d4e5f67001","type":"text","text":"### Hyperparameters (超参数总结)\n**需要人为设定，不从数据学习：**\n\n1. **Learning Rate (eta)** - Week03\n   - Controls GD step size\n2. **Polynomial Degree** - Week04\n   - Controls model complexity\n3. **Lambda (lambda)** - Week04\n   - Controls regularization strength\n\n**如何选择？**\n- Cross-Validation (Week05)\n- Grid Search: try many combinations\n- 看 validation error 最小的组合","x":-280,"y":1370,"width":460,"height":260,"color":"3"},

		{"id":"a1b2c3d4e5f68000","type":"group","text":"Key Formulas (必背公式)","x":260,"y":1350,"width":540,"height":400,"color":"3"},
		{"id":"a1b2c3d4e5f68001","type":"text","text":"### Formula Sheet (考前必背)\n\n**1. Normal Equation:**\ntheta = (X^T * X)^(-1) * X^T * y\n\n**2. GD Update:**\ntheta_new = theta_old - eta * dJ/d(theta)\n\n**3. Gradient (Linear Reg):**\ndJ/d(theta_j) = (2/n) * SUM((y_hat_i - y_i) * x_ji)\n\n**4. L2 Gradient Addition:**\n+2 * lambda * theta_j\n\n**5. 2x2 Matrix Inverse:**\n[a b; c d]^(-1) = (1/(ad-bc)) * [d -b; -c a]\n\n**6. Centroid Defuzzification:**\nOutput = SUM(FS_i * Center_i) / SUM(FS_i)\n\n**7. trimf(a,b,c) - rising:**\nmu = (x - a) / (b - a)\n\n**8. trapmf(a,b,c,d) - rising:**\nmu = (x - a) / (b - a)\n\n**9. Precision = TP/(TP+FP)**\n**10. Recall = TP/(TP+FN)**\n**11. F1 = 2PR/(P+R)**\n**12. R^2 = 1 - SS_res/SS_tot**","x":280,"y":1370,"width":500,"height":360,"color":"3"},

		{"id":"a1b2c3d4e5f69000","type":"group","text":"Common Mistakes (常见错误)","x":860,"y":1350,"width":500,"height":480,"color":"1"},
		{"id":"a1b2c3d4e5f69001","type":"text","text":"### Common Mistakes (常见错误)\n\n**Fuzzy Logic:**\n1. AND = MIN (not multiply!)\n2. OR = MAX (not add!)\n3. trapmf plateau区间 mu=1\n4. trimf在a和c处 mu=0，不是undefined\n\n**Gradient Descent:**\n5. 别忘了 (2/n) factor in gradient\n6. L2 regularization: +2*lambda*theta_j\n7. Don't regularize theta_0 (bias term)!\n8. 先算 y_hat，再算 error，再算 gradient\n\n**Normal Equation:**\n9. X matrix 第一列是全1 (for bias)\n10. det=0 时矩阵不可逆！\n\n**Metrics:**\n11. Precision vs Recall 别搞反\n    P = TP/(TP+FP), R = TP/(TP+FN)\n12. MSE unit是平方，RMSE才是原单位\n13. R^2可以是负数 (比mean还差)\n\n**Overfitting/Underfitting:**\n14. Train LOW + Test HIGH = Overfitting\n    (不是 Train HIGH + Test LOW!)\n15. lambda大 -> underfitting (not overfit)","x":880,"y":1370,"width":460,"height":440,"color":"1"},

		{"id":"a1b2c3d4e5f6a001","type":"text","text":"### AI Hierarchy (AI 体系)\n\nAI (人工智能)\n  |- Expert Systems (Week01)\n  |- Fuzzy Computing (Week01)\n  |- Robotics\n  |- NLP\n  |- Machine Learning (Week02-05)\n       |- Supervised\n       |    |- Linear Regression (Week03)\n       |    |- Classification\n       |- Unsupervised\n       |    |- Clustering\n       |    |- Dimensionality Reduction\n       |- Reinforcement Learning\n       |- Deep Learning\n            |- Neural Networks\n            |- CNNs, RNNs, Transformers","x":-1040,"y":1350,"width":380,"height":430,"color":"6"},

		{"id":"a1b2c3d4e5f6b001","type":"text","text":"### GD + L2 Regularization 计算模板\n**（Q1 25分计算题模板）**\n\nGiven: data points, eta, lambda, initial theta\n\n**Step 1:** y_hat = theta_0 + theta_1*x1 + theta_2*x2\n**Step 2:** error_i = y_hat_i - y_i (for each point)\n**Step 3:** grad_0 = (2/n)*SUM(error_i)\n**Step 4:** grad_1 = (2/n)*SUM(error_i * x1_i) + 2*lambda*theta_1\n**Step 5:** grad_2 = (2/n)*SUM(error_i * x2_i) + 2*lambda*theta_2\n**Step 6:** theta_0_new = theta_0 - eta * grad_0\n**Step 7:** theta_1_new = theta_1 - eta * grad_1\n**Step 8:** theta_2_new = theta_2 - eta * grad_2\n\nNote: theta_0 (bias) does NOT get regularization term!","x":-300,"y":1700,"width":500,"height":400,"color":"1"},

		{"id":"a1b2c3d4e5f6b002","type":"text","text":"### Fuzzy Logic 计算模板\n**（Q2 25分计算题模板）**\n\nGiven: input values, membership functions, rules\n\n**Step 1 - Fuzzification:**\nFor each input, compute mu for each fuzzy set\nusing trimf or trapmf formulas\n\n**Step 2 - Rule Evaluation:**\nFor each rule (IF A AND B THEN C):\nFS = MIN(mu_A, mu_B)\n\n**Step 3 - Aggregation:**\nCollect all (FS, output_center) pairs\n\n**Step 4 - Defuzzification:**\nCrisp Output = SUM(FS_i * Center_i) / SUM(FS_i)\n\nExample:\nFS1=0.4, Center1=20; FS2=0.6, Center2=50\nOutput = (0.4*20 + 0.6*50)/(0.4+0.6)\n       = (8+30)/1.0 = 38","x":260,"y":1800,"width":500,"height":430,"color":"1"}
	],
	"edges":[
		{"id":"e1b2c3d4e5f60001","fromNode":"a1b2c3d4e5f60003","fromSide":"bottom","toNode":"a1b2c3d4e5f64004","toSide":"top","color":"1","label":"Q1 Source"},
		{"id":"e1b2c3d4e5f60002","fromNode":"a1b2c3d4e5f60003","fromSide":"bottom","toNode":"a1b2c3d4e5f65005","toSide":"top","color":"1","label":"Q1 Source"},
		{"id":"e1b2c3d4e5f60003","fromNode":"a1b2c3d4e5f60004","fromSide":"bottom","toNode":"a1b2c3d4e5f62004","toSide":"top","color":"1","label":"Q2 Source"},

		{"id":"e1b2c3d4e5f61001","fromNode":"a1b2c3d4e5f61001","fromSide":"bottom","toNode":"a1b2c3d4e5f61002","toSide":"top"},
		{"id":"e1b2c3d4e5f61002","fromNode":"a1b2c3d4e5f61001","fromSide":"bottom","toNode":"a1b2c3d4e5f61003","toSide":"top"},
		{"id":"e1b2c3d4e5f61003","fromNode":"a1b2c3d4e5f61001","fromSide":"bottom","toNode":"a1b2c3d4e5f61004","toSide":"top"},
		{"id":"e1b2c3d4e5f61004","fromNode":"a1b2c3d4e5f61001","fromSide":"right","toNode":"a1b2c3d4e5f61005","toSide":"top"},
		{"id":"e1b2c3d4e5f61005","fromNode":"a1b2c3d4e5f61001","fromSide":"right","toNode":"a1b2c3d4e5f61006","toSide":"top"},

		{"id":"e1b2c3d4e5f62001","fromNode":"a1b2c3d4e5f62001","fromSide":"right","toNode":"a1b2c3d4e5f62004","toSide":"left"},
		{"id":"e1b2c3d4e5f62002","fromNode":"a1b2c3d4e5f62001","fromSide":"bottom","toNode":"a1b2c3d4e5f62002","toSide":"top"},
		{"id":"e1b2c3d4e5f62003","fromNode":"a1b2c3d4e5f62001","fromSide":"bottom","toNode":"a1b2c3d4e5f62003","toSide":"top"},
		{"id":"e1b2c3d4e5f62004","fromNode":"a1b2c3d4e5f62004","fromSide":"bottom","toNode":"a1b2c3d4e5f62005","toSide":"top"},

		{"id":"e1b2c3d4e5f63001","fromNode":"a1b2c3d4e5f63001","fromSide":"bottom","toNode":"a1b2c3d4e5f63002","toSide":"top"},
		{"id":"e1b2c3d4e5f63002","fromNode":"a1b2c3d4e5f63001","fromSide":"bottom","toNode":"a1b2c3d4e5f63003","toSide":"top"},
		{"id":"e1b2c3d4e5f63003","fromNode":"a1b2c3d4e5f63001","fromSide":"right","toNode":"a1b2c3d4e5f63004","toSide":"top"},
		{"id":"e1b2c3d4e5f63004","fromNode":"a1b2c3d4e5f63001","fromSide":"right","toNode":"a1b2c3d4e5f63005","toSide":"top"},
		{"id":"e1b2c3d4e5f63005","fromNode":"a1b2c3d4e5f63001","fromSide":"right","toNode":"a1b2c3d4e5f63006","toSide":"top"},

		{"id":"e1b2c3d4e5f64001","fromNode":"a1b2c3d4e5f64001","fromSide":"bottom","toNode":"a1b2c3d4e5f64002","toSide":"top"},
		{"id":"e1b2c3d4e5f64002","fromNode":"a1b2c3d4e5f64001","fromSide":"bottom","toNode":"a1b2c3d4e5f64003","toSide":"top"},
		{"id":"e1b2c3d4e5f64003","fromNode":"a1b2c3d4e5f64001","fromSide":"right","toNode":"a1b2c3d4e5f64004","toSide":"top"},
		{"id":"e1b2c3d4e5f64004","fromNode":"a1b2c3d4e5f64001","fromSide":"right","toNode":"a1b2c3d4e5f64006","toSide":"top"},
		{"id":"e1b2c3d4e5f64005","fromNode":"a1b2c3d4e5f64004","fromSide":"bottom","toNode":"a1b2c3d4e5f64005","toSide":"top"},
		{"id":"e1b2c3d4e5f64006","fromNode":"a1b2c3d4e5f64001","fromSide":"right","toNode":"a1b2c3d4e5f64007","toSide":"top"},

		{"id":"e1b2c3d4e5f65001","fromNode":"a1b2c3d4e5f65001","fromSide":"bottom","toNode":"a1b2c3d4e5f65002","toSide":"top"},
		{"id":"e1b2c3d4e5f65002","fromNode":"a1b2c3d4e5f65001","fromSide":"bottom","toNode":"a1b2c3d4e5f65003","toSide":"top"},
		{"id":"e1b2c3d4e5f65003","fromNode":"a1b2c3d4e5f65002","fromSide":"bottom","toNode":"a1b2c3d4e5f65004","toSide":"top"},
		{"id":"e1b2c3d4e5f65004","fromNode":"a1b2c3d4e5f65003","fromSide":"bottom","toNode":"a1b2c3d4e5f65004","toSide":"top"},
		{"id":"e1b2c3d4e5f65005","fromNode":"a1b2c3d4e5f65001","fromSide":"right","toNode":"a1b2c3d4e5f65005","toSide":"top"},
		{"id":"e1b2c3d4e5f65006","fromNode":"a1b2c3d4e5f65001","fromSide":"right","toNode":"a1b2c3d4e5f65006","toSide":"top"},
		{"id":"e1b2c3d4e5f65007","fromNode":"a1b2c3d4e5f65005","fromSide":"bottom","toNode":"a1b2c3d4e5f65007","toSide":"top"},
		{"id":"e1b2c3d4e5f65008","fromNode":"a1b2c3d4e5f65006","fromSide":"bottom","toNode":"a1b2c3d4e5f65007","toSide":"top"},

		{"id":"e1b2c3d4e5f66001","fromNode":"a1b2c3d4e5f66001","fromSide":"bottom","toNode":"a1b2c3d4e5f66002","toSide":"top"},
		{"id":"e1b2c3d4e5f66002","fromNode":"a1b2c3d4e5f66001","fromSide":"bottom","toNode":"a1b2c3d4e5f66003","toSide":"top"},
		{"id":"e1b2c3d4e5f66003","fromNode":"a1b2c3d4e5f66001","fromSide":"right","toNode":"a1b2c3d4e5f66004","toSide":"top"},
		{"id":"e1b2c3d4e5f66004","fromNode":"a1b2c3d4e5f66001","fromSide":"right","toNode":"a1b2c3d4e5f66005","toSide":"top"},
		{"id":"e1b2c3d4e5f66005","fromNode":"a1b2c3d4e5f66001","fromSide":"right","toNode":"a1b2c3d4e5f66006","toSide":"top"},

		{"id":"e1b2c3d4e5f6c001","fromNode":"a1b2c3d4e5f61006","fromSide":"right","toNode":"a1b2c3d4e5f63001","toSide":"left","color":"6","label":"NN -> ML"},
		{"id":"e1b2c3d4e5f6c002","fromNode":"a1b2c3d4e5f63003","fromSide":"right","toNode":"a1b2c3d4e5f64001","toSide":"left","color":"6","label":"Supervised -> LinReg"},
		{"id":"e1b2c3d4e5f6c003","fromNode":"a1b2c3d4e5f64004","fromSide":"right","toNode":"a1b2c3d4e5f65001","toSide":"left","color":"6","label":"GD -> Regularization"},
		{"id":"e1b2c3d4e5f6c004","fromNode":"a1b2c3d4e5f65003","fromSide":"right","toNode":"a1b2c3d4e5f66001","toSide":"left","color":"6","label":"Overfitting -> Metrics"},
		{"id":"e1b2c3d4e5f6c005","fromNode":"a1b2c3d4e5f64006","fromSide":"bottom","toNode":"a1b2c3d4e5f67001","toSide":"top","color":"3","label":"Hyperparameter"},
		{"id":"e1b2c3d4e5f6c006","fromNode":"a1b2c3d4e5f65007","fromSide":"bottom","toNode":"a1b2c3d4e5f67001","toSide":"right","color":"3","label":"Hyperparameter"},
		{"id":"e1b2c3d4e5f6c007","fromNode":"a1b2c3d4e5f66006","fromSide":"bottom","toNode":"a1b2c3d4e5f67001","toSide":"right","color":"3","label":"For tuning"},
		{"id":"e1b2c3d4e5f6c008","fromNode":"a1b2c3d4e5f64003","fromSide":"bottom","toNode":"a1b2c3d4e5f68001","toSide":"top","color":"3","label":"Formula"},
		{"id":"e1b2c3d4e5f6c009","fromNode":"a1b2c3d4e5f64004","fromSide":"bottom","toNode":"a1b2c3d4e5f68001","toSide":"top","color":"3","label":"Formula"},
		{"id":"e1b2c3d4e5f6c010","fromNode":"a1b2c3d4e5f65005","fromSide":"bottom","toNode":"a1b2c3d4e5f68001","toSide":"right","color":"3","label":"Formula"},
		{"id":"e1b2c3d4e5f6c011","fromNode":"a1b2c3d4e5f62004","fromSide":"bottom","toNode":"a1b2c3d4e5f68001","toSide":"left","color":"3","label":"Formula"},
		{"id":"e1b2c3d4e5f6c012","fromNode":"a1b2c3d4e5f68001","fromSide":"bottom","toNode":"a1b2c3d4e5f6b001","toSide":"top","color":"1","label":"Q1 Template"},
		{"id":"e1b2c3d4e5f6c013","fromNode":"a1b2c3d4e5f68001","fromSide":"bottom","toNode":"a1b2c3d4e5f6b002","toSide":"top","color":"1","label":"Q2 Template"},
		{"id":"e1b2c3d4e5f6c014","fromNode":"a1b2c3d4e5f62005","fromSide":"bottom","toNode":"a1b2c3d4e5f69001","toSide":"left","color":"1","label":"Avoid"},
		{"id":"e1b2c3d4e5f6c015","fromNode":"a1b2c3d4e5f64005","fromSide":"bottom","toNode":"a1b2c3d4e5f69001","toSide":"top","color":"1","label":"MCQ Prep"},
		{"id":"e1b2c3d4e5f6c016","fromNode":"a1b2c3d4e5f66005","fromSide":"bottom","toNode":"a1b2c3d4e5f69001","toSide":"right","color":"1","label":"Avoid"}
	]
}