the dimension of the reduction. So, yeah, this question. Now, if you have more time than I do, why is it even bigger? Because you can't show more than 3D, right? So, maximum 3D, you can. X, Y, Z. One way is to show the features that make it the most important feature, which we call as my hands, which is the wings. The other right way is each other's reduction. What does it mean? It means that you have 100 people. I mean, you have 100 people. And you bring those under the feature. If you make a mistake, that means that their values are going to change because all the dimensions are real values. But at the end, like that transform, they work. This one is called feature reduction. Okay? So, feature selection means that you keep the data set as is, just set a tree of those, and then you show the other ways using feature reduction. How do you do it? And keeping all the, let's say, the three dimensions. In the first method, like if you would have the data, you see the original piece, but only see each other in the future. But in the second method, if you visualize, your originality is not changed. Okay. Because they are in other series. Okay. So, in the first method, for example, I want to do Gluster. I still use all the features to Gluster, but just to visualize, I select a few of them, right? If you are just talking about the visualization, yes. For visualization, you cancel anything more than three. But sometimes you do feature reduction, or feature, let's say, selection for modeling. Okay. For modeling. That could be different. Okay. That means that your radius, you don't want to make your digitalization. In terms of the modeling, sometimes maybe you can do reduction, or selection, but you have three dimensions. Okay. Okay. Thank you. So, the aim is here. Okay. So, I think last time, we discussed about the two important paradigms of the human race. One is called the, what is called the, and the other one is called uncivilized. Right? So, and for the supervised dimension that, like our data has labels, and I'm going to focus a little bit more about the supervised. So, in general, all supervised tasks have the recognition problem or classification. So, what is the classification? Classification means that we have some data like this, and we want to classify it to class. Red and green. Right? Like class A, class B. Who will really want to have the class. But if our, so here, our target values are zero and one. Okay. Well, maybe class one, two, three. Okay. It's not like classes. But this one is a binary classification. Sometimes our data is not the, only classes. But you want to predict value like Y, which is the, for example, a price house. Based on the area, you want to predict the price of that property. Okay. Here, Y is not a class. It's not zero, one. It is a real number, or maybe integer number. Okay. That's called regression problem. So, as you see here, in classification problems, our target right, some classes, class one, class two. But here, it wants two real numbers. Okay. Like flow. So, I think we have, to example here, I'm not sure like, to discuss about this last time, but, and it's going once again. So, what we have, we have different properties in our data sets. And we want to see that, can I predict that, for each properties, we have some features, like a square footage, number of bedrooms, does it have swimming pool or not. And, what is the house price in the USA? Right. Okay. So, and therefore, the second observation, the second property. Okay. And, and so on and so forth. Okay. So, here we call this guys as X, our features, and this guy has a target. And as you see, it's a real number. So, it's, it's not classification, right. It is a regression. As sent in here, I'm not sure it's readable for the people at the back. Again, like, suppose that we want to, we have a data set, it has some features for each patient, but some information, like agent, patient, gender, admission type, diagnosis category, like, for example, ages 75, gender is made, admission type is elective, it's not the emergency, right. Okay. So, and then, initial diagnosis is, are diseases. Okay. So, for the second patient, 22, male, like, admission type is emergency, and injury, is a diagnosis category. So, for each observations, for each instance, can you just focus here, please? Thank you. For each instance, we want to check the length of the stay in the hospital, how many days. So, if I have an observation like this, it's going to be 4.6. If I have such a thing, it's emergency, 2.6, and that's one as well. Then, what is the idea? We have a data set, we data like this. Then, the trainer model, based on this, you can then, suppose that, and the patient, I go to the hospital, and based on my situation, or my status, we're going to check that, how many days of work. The model, we're going to predict that, what will be the length of stay. Okay. So, the values here, again, are, oh, maybe seven days, I mean, six days, like, some hours. That's why, it's not the classification. That was something like, one, two, three, four. Again, like, okay. So, this is the example, and, so, you can color this one, or, what is this one? Okay. Like, suppose that we have, different, data sets, right? All of these, like this, or, length of stay. Okay. So, this one is, another example, and, here, we want to know that, what is the risk, based on the job card, a smoker, how else wants to say, give some, some score, to the risk, right? Like, something one, two, three, four, five. Like, higher, maybe, more risky. Okay. For example, this job is not too much risky. This one, this one is not too much risky, but, like, the others are getting. So, here, it is our target, this class, um, integer, some categories, it's the classification. Okay. What this one is saying, but it depends on, what is our problem, ethics, migration problem, ethics, execution problem, we can create different models, what I think is that, we can get our data set, and train a model. There are different ways, maybe our model is decision-free, maybe it's a linear regression, maybe it's neural network, okay, and so on and so forth. One of these models, as I mentioned, is neural network, and what is this neural network? You cannot discuss in detail about that one, but, we have some inputs, suppose the green ones, are the features, okay, like age of person, initial diagnosis, and so on and so forth, and the output, is how many days can I stay at? So, so, this is called input layer, and the output layer, is something that the model, meanwhile, between these two, we might have different layers, one layer, two layer, four, ten layers, okay, and those are called VW layers, so some of those, consider this one as there, something like that. If we have too much layers, it's called input layer, okay, rather than one VW layer, if you have too much layer, it's called V2. Okay, V2. Model is green, it takes some input, and maps that one to some output. Okay, here what's happening, we don't know. Okay, so, in other words, this part is just a function for us, like a function, right, if it's equal wide, alright, so this is our edge. If it takes edge, I can write that one to, let me know if you have this slide. Okay, so, in other words, we have a model here, this model can be normal, right, and it takes our features, convert that one to some ones. Each model, or, like a model sometimes called the function, or, we call that one hypothesis, okay, so hypothesis simply means the function. So, as you see here, this model of this function takes X, I convert that one to R. We have different models, it could be normal network, or it could be decision trees. Decision tree is a simple model. You just say that, okay, for example, let's say some of the, some of the rules. If X is less than this, then check, X1 is less than, for example, is there a show, check X2, if X is less than something, and then check the others, right, and then I then say that, based on these rules, the prediction of the model gonna be this one. Okay, so, I think I can, yeah, okay, so I can explain here, like, each of this, I mean, this F is a function, right, so that function, suppose that that function is a linear function, something like this, okay, and here, what is important for us, is that this slope, still called the function, and it's intersection, right, so, for example, suppose that we have some points, like just one point, we have some points, and then, for those points, I feed this line, okay, and that line is, or that function is 1.8X plus 1, okay, or maybe I use just this one, or maybe I use this function, either of these functions, this could be one hyper-presence, but the correct one is that, the one which exactly hit the points that I have. In other words, if it's not exactly hit, maybe the error of the points and the model should be minimal. Okay, so, what I want to mention is that each of these lines are determined by two parameters. One parameter is theta zero, and the other one is theta one, because zero is the slope of this function, sorry, theta one is the slope of this function, how much is it steep, how much is like that, and the other one shows that, how much is, it differs from the origin, okay? So, if we know that theta values, in other words, we can determine what is our function. Sometimes, not the linear function, it can be, you see, it is not a linear function, right? So, we have polynomial here. It's x one, x two, x one score, x three score, and so on and so forth. It's not like a linear function, it's like a, let's say, a function like, but this one is just a linear function, like a, as you see, but this one is not, why? Because we have a square, and also, we have a square values here. It's kind of like, a polynomial, a deeply true, so, the other thing is, I mean, it could be something like, this, x, I'm trying, we have little points here, I can, I can put theta one, like this one, which is, for example, two, x, plus, or maybe, rather than this function, I can, for example, a nonlinear function, like this, which comes from, for example, three, x, two, plus five, right? This one is, like it's not there, linear, it's like a, there's a square, or, maybe, more than one, but this one is, I know that, if I use this, nonlinear function, it can be better, for this problem. Okay, so, I'm just example. So, this is the one you mentioned, same thing, like, supposedly, rather than x, you have x1 and x2, if it's more than, one teacher, rather than in line, it's gonna be like a plate. Okay? If it's a plate, it means that that's linear. But, if it's something like, simple, right, or happy simple, it's gonna be nonlinear. Okay? We're gonna talk about that one. So, what is important here, is that, like, at the end, if I know that, the value of people is zero, people are one. I can understand that, right? If I just need, because you are different one, it's gonna be, if I have, because you're different three, it's gonna be, something like this. And, if I add more, okay, if it is, like, x3, it's gonna be, something like, a, a figure of three. Right? Like, more than, normal for this. Okay? So, training is nothing more than determining those features, those parameters. I think this one is the, talking about the same. What is important here, is that, like, we split our data in two parts. One part is called the training data. So, for example, suppose that we want to predict y, using x1 and x2. We have a couple of data points here, like, say, 10,000 data. We take, 20% of that one as our test data, and 80% as the training. We use this part, to train the model, and the regular edge. We can feed this input, to predict what would be then, because these are the points that we haven't involved there in the training. So, in other words, those are new points for us. Those are unseen data. Does that make sense? Any question? Okay. So, that's what you see here, as that. You've already seen some data, and we have some unseen data, or new data. And for this, already seen data, based on that one, we train our models, and then we try to predict on new data. Okay. So, I think the guys are, talking about the same thing, but, I will discuss about the microphone. I have some slides here, like, let's say, seven, one, two, one, five slides I get. I can get back to this one, and explain what is that. So now, I'm skipping, but I gotta get back. It's a simple thing. So that's why, for me, first, we can discuss about linear regression, and then I can get back to that one. Okay. So, the first type of models we are going to learn is called linear regression. So, what is that? That means that, you want to predict some target values, and what are the float numbers? So, the problem is the regression. Okay. And then, you want to see that, can you feed a line for those points? Something like this, or if the points are like this, maybe like this, or if the points are something like this, probably, relationship is not the linear, you can feed a non-linear function. So, again, this is the same slide, superwise, non-superwise, and if our output is quantity, it's going to be regression. If it's a category, it's going to be classification. And then, this isn't any new solution. Okay. So, superwise, it's a regression called classical regression. Any question on this slide? Okay. So, this is the agenda for the linear regression models. Okay. So, first, we want to understand what is the linear regression, and after that one, the different type of solutions for linear regression. So, one method is called this square solution, and the other one is called gradient solution. However, this square can be simple linear regression, polynomial, or multi-variant linear regression. Okay. So, this is the agenda for today's discussion. So, very same. What is linear regression? So, as you see here, the linear regression is that we have some observations, right? And some points, and those points are independent, means that they are not depends on each other, right? So, this point is independent. And, okay. Okay. So, points. If you want to say, like, we have some points here, the blue ones, and we have X, and we have Y. X is called out-in rivals, or sometimes we call that independent rivals. Y is called dependent rival, or ultimate. Why we call that one? Why is that dependent? Y depends on X. That X depends on what? This is Y equal to X. Right? We call it X, and based on that one, which something like this Y equal to Y equal to X plus Y. Okay. X is called Y is going to be dependent. In other words, Y is dependent. So, always we have some input features, we call that one independent rivals. And, we have a rival, which is called the dependent rival, or these are different names that we call. during this course, probably in many areas. Sometimes, I say target. Target means Y. Okay. Or sometimes we call it that part, same thing. Okay. So, as I mentioned, it could be different things. Sometimes, we see that the relationship between the poles are like this. I can I can fit a line, or a line like this. Sometimes, I use another function, because I see that relationship is not too much. Many are so, let's fit with non-linear function. So, for example, this is just a very simple example, and we want to see that if the temperature in general, what it shows, it shows that if the temperature is going high, increases, the sales of ice cream increases. Okay. So, it's naturally true. So, for example, when the temperature is 12, there are 200 sales of ice cream. If it's 26, there are 600 sales of ice cream. So, we have some points here. Then somebody asks, okay, can you approximate the function? Which tells me that in each temperature, even if that temperature is not one of these points, what would be the prediction for the sale? Okay. For example, we are, I don't know, in July 15, the degree here is 25, and we want to know that probably sales of ice cream begin to happen. Okay. Maybe I don't see 25 here. Okay. But what I can do, I can fit a line and after fitting that line, I can check that. Here is 25. Let's go and see that what would be the set of 500. Make sense? So, feeding the line is called train. And then for 25, getting the output for 25 is called prediction. Because 25 is a new point. Okay. We'll test it. Make sense? Yes? Anyone any question? Okay. So, this is just a very simple. Sometimes, rather than temperature, we might have more than one feature. Temperature and let's say area. Temperature and humidity. Temperature, area and humidity. I mean, I mean that like rather than one feature, we have our input features are more than one. Okay. It's called multi-primary problem for multi-primary. Okay. Well, like this. For example, we want to see the price of different cars, used cars. Here, this is our output and which for dependent feature and that's dependent age, distance and width. Okay. So, simply, we have a data set based on this data set. We learn what is the function and now, if you want to know that, okay, you see, you want to get a car. So, again, all you can do that one, you can pass your feature to the train model and it's going to say that what will be there. I think there are some websites for this, right? This gives you the price of used cars, predicts like that. Space and machine learning. Okay. Train the model and then for unseen data or new cars, you can predict what will be the price for that. What I want to mention, sometimes our problem, only rival, sometimes we have more than one input feature. It's called multi-primary. I see that here, the relationship is kind of linear. For the price, maybe you can find a linear function which predicts the price. Okay. What I mean here is that I can find a function like this. A0 plus, sorry, alpha 0 plus alpha 1 times age plus alpha 2 times distance plus alpha 3 times weight. If you multiply this and do summation, you're going to get the price. Okay. I want to see that based on this feature, age, distance, and weight, can I determine a function which beats for all on all all the points here? So what is important? If I could know that what is the alpha 0 to alpha 3, that means I have that function. In other words, what is important for me is that determining the values alpha 0 to alpha 3. And those are the parameters of the model. That's why we say that our model is nothing more than parameters. Sometimes we decrease our model to parameters. It means that if you determine the parameter, you know what is your linear. If you know that A0, A1, A2, and A3, okay, then together and you're going to get this function. Okay? Any questions? Okay. So, this is just an example, but in high level, what is important for us, we are looking for a function Y or function F which takes X, XR or our age, distance, and weight and determine what is the theta. Okay? So, as you see here, F depends on X and theta. If I know X and theta, I know that what is my output point. What is objective? To explain that, what is important for me, let me talk about this example. So, suppose that you have this orange line, how do you know that your your figured function is good? How do you know that? There, alright? So, if you check that, how much difference between the blue and orange, right? So, for this point, it's almost zero. For this point, suppose it's one, here is one, zero, it's two, one, zero, zero. Alright, for this one, it's three. Put them all together and bring in our soul. In total, I have this much error. If it's a big number, it shows that your model is not good. If it's a small number, it shows that, oh, your fitting is good. You don't have too much error. Right? So, our objective is, here is that, the difference between prediction of the model and the labels, okay, now the difference between the target and output of the models should be small value. And that is called error. Error of the model should be small value. Okay? The difference between grand truth and the model prediction. The grand truth is the blue ones. Model prediction is the model prediction, right? So, the difference between grand truth and model prediction should be small value. All the points that you have. Okay. So, you can do something. You can find the difference between the grand truth and the model output. Reach point and then find the summation. Okay? This is called the sum of absolute errors. Okay? Find the sum of errors or sum of absolute errors. Sometimes, we find the sum of errors, but here, when I get the error for each point, I do a square of that. Okay? So, something like this. The distance, the difference between y i and y hat. Okay? So, y i is what we have in our what the model to the y hat has. Okay. So, consider y hat is the model prediction and y is our grand truth. The difference between y and y hat for every point point one to n in that each of this point and then this square. Okay? So, for example, for example, if the price of the first card is thirteen hundred thirteen point five, but the model tells thirteen is going to be five hundred squared for the first point. Plus the difference of this and the model prediction. Right? Plus squared that one and plus for the table. So, this is just telling the same thing and we call that one sum of the squared error. It is very common terminology we use. Okay? So, always if you want to find the error of the model for regression problem, the indicator here is that what is your sum of squared error? If it's a higher value, it shows that your model is not good. This is low value, lower value shows it's good. And higher and lower means that the difference between the model prediction and ground truth, all the points are slim. We are looking for a function like this, but what is important, the important thing is that what is this alpha one to alpha three? And based on those alpha one to alpha three, we can determine what is the error of the model. So, the base model is that the one which for this error is close to zero. It's ideal. Okay? But sometimes probably it's not possible to feed all the points. Right? Because some of them are like, our relationship is not linear. Of course, we're going to have some errors. It's, we can't, we know about that. Right? But closer to zero is the best. Any questions? So, what is the exact mechanism of finding those? Good question. How we can find those parameters? That's the, the next thing that we're going to discuss. Okay. So, the question here is that, how we can find this alpha zero, alpha one, alpha two and alpha three? So, the optimal values for these parameters. Okay? So, there are two methods for this. One is called this square solution or it's called most four. And the other one is called drag and resistance. Okay? So, first I'm going to explain this on this square. Okay? So, sometimes I'm explaining something like this. Five or that's it. Okay. So, multi-variate, right? Multi-variate or zero? Okay. Let's make it simple, something like this, this problem and something like this. Proceeded sample, then I can go into detail on that. Okay. What we have, we have one X. Oh, sorry, can you press that button? Suppose we have example like this. Okay. What I have here, I have X and I have Y. Each X, I know what is the Y. I want to see that what is the best linear function? Which I can feed. In other words, I'm looking for the best slope and best interception. A zero and best A one. Question, which you're afraid measure, how we can find the optimal alpha zero and alpha one? If the line which has the smallest error would be the best, but what is that line? We're looking for that. I had a problem like this. For example, like this. And then let's get back to that's the same, right? That's the same. We have X and we have Y and these are our samples. X one, X two, and Y one and Y. Important for me is that okay, as you see, alpha. I'm looking for a function like this, which alpha is intercept. Beta is the slope. Y hat is the model prediction and YR is the ground truth. Okay. How we can find a function like this? I'm looking for a function like this, but at then what is important for me is that the difference between the target or the ground truth and the model prediction so this one is the target and this one is the model prediction. Y hat or Y I have. So if I get the square of this for all the samples, this error should be small number, the minimum. Okay. Oh, I can find the minimum function. If you have a function, you can find the minimum of that. But then we can start having a function like this. What is it called? X. I mean like look at here this is X equals for example this here. This one is X equals zero. In other words X equals zero is the point that the slope of this function is zero. Maybe sometimes rather than this, something like this. It's equal to the point that the slope there is zero. This is the slope. Okay. Other forms here for example I have some slope. It's not zero. Here I have some slope. The slope means just let's say that I can find this one. This is the point that the deviation of the function there is zero. The deviation of the function is zero. If I find the derivative of this so it means I want to measure that. Okay. So what do you need to do? You need to find the slope there. You can have something like this and then you want to know that where is the optimum of this function. What do you need to do? You need to find the byte file. We call sometimes we call it byte file as normal white just notation. Okay. So what is the white prime? White prime means two times this. Okay. Okay. you have x to the power of n is white prime. It's going to be nx. nx. nx. nx. nx. nx. nx. nx. nx. nx. nx. nx. nx. nx. it shows that the mean of this function is going to be n. If you want to, if you have a function if you. If you have a function for any function which has some rivals if you want to find the mean of that just take the derivative of that function. Okay, like what I did there. And then see that where the derivative is zero, it's going to be one of your optimal points. That's there from the high school math, right? We know what that is. Okay. So, this indicator for us to find the optimal function. So, this is my error, and I am looking for the points which makes this error optimal. What I can do? Simple. I need to find the derivative of E and set that one as zero and see that what it returns. Okay, let me explain further. So, now we know that just let's substitute the values. Okay. So, we have yi, and I know that yi is alpha plus beta x. Let's say y hat as alpha plus beta x, right? Because y hat is our function. This one is y hat. So, just substitute here. Then, I have this function error in this program. What I need to do? I'm going to see that what is the optimal alpha and what is the optimal beta? What is the best alpha and beta? To make this error, nothing, exactly zero but optimal alpha. Okay. So, what I need to do? I need to find the derivative of this E prime with respect to alpha and beta. So, I find the derivative of E with respect to alpha. Let's say that that one as zero. Why? Because I'm looking for the best alpha. And same thing for beta. To get there, zero. It is very similar to what we have on the white board. Because rather than just y here, we have E. There we have y. Here we have E. What y I'm looking for? Normal for derivative of E with respect to y parameters. Okay. The other one is beta. Just set as zero. I'm explaining one of those and the other one is also similar. So, if you have such a thing and you want to find the derivative of this with respect to alpha, it's going to be two times this derivative of this. Suppose it's something like this x to the power of n. What is the derivation of that? It's going to be n times x n minus one. So, here we have the same thing. It's going to be two times derivative of this times derivative of this n minus one. Okay. So, if you do like that, it's going to be two times the derivation of this with respect to alpha is going to be minus one and this one. What do we have? We have E plus y i minus a i x plus alpha and alpha plus beta x. So, then I'm looking for optimal alpha and alpha. So, what I can do? I can find the issue of this function with respect to alpha. If I do like this, that means that all these things I do like this, I'm looking for derivative with respect to alpha. It's going to be something like suppose it's going to be j x and this is f x and you have x in the same component. Okay. So, always derivative t is going to be times f prime x, for example, equal x to d prime of x is going to be f prime of what is our f x here? This is f x. Okay. For x, respect to x is one. That's right. Consider this correlation of strength. I have a function like this. What could be the derivation of this? It's going to be two times this point itself. That's the point this is over our plus. Okay. So, the only thing is that here. What is the derivative? This one is zero. What is this called? This. Minus one. One, right? Because now I can't add this. One, two. This is going to be zero. Now, what I have here is I from, I want to minus my i is going to be zero plus f prime x. I is from one, two. Here we have minus two. My i is two and this is one or five. Okay. One of those in one side of it, for example, I move down to one, two, and one. This is going to be something like this. That's what we see here. Because this one, you say something like this. Alpha plus alpha plus alpha n times. What is going to be n alpha and plus that's what we see. Okay. We have this one. If you do the same thing for beta, you're going to get this one. Okay. Any question on this? All right. Okay. Let's go. Okay. So, now we have two equations. One equation is this one. Another equation is this one. If you solve these equations together, it is something like this, for example, 2x1 plus 3x2 equals zero. The other one is 5x1 plus, I don't know, 6x2 equals zero. You have two equations and two variables. You can solve it. Okay. If you do that one, considering this two, the optimal value for alpha is going to be y bar. This is different from this way. Y bar means that average of x. Okay. Minus beta average of x. How we can get the alpha itself? Beta itself means covariance of xy divided by variance of xy. And this is the definition. Okay. I think here I can explain easily. So, suppose just this example. All right. And I want to know that what is the optimal alpha and what is the optimal beta. Okay. Look at here. So, to get the optimal alpha, you need to know what is the average of y's and average of x. So, I have calculated the average of x. All right. So, it's getting to be 3. 1 plus 2 plus 3 plus 4 plus 5 divided by 5. Average of y's is getting to be 2.46. Okay. Then it's good. I have y bar. I have x bar. The only thing is beta. I don't know what is the beta. So, but I know that beta means covariance of x and y divided by variance of x. And variance of x is this equation. So, I can calculate variance of x. So, it's going to be 1 over n minus 1 on over 4. And the difference between each x and its average, which is 1 minus average 3 squared. All right. Plus the other ones. 2 minus 3 squared and so on and so forth. If you do that one, it's going to be 2.5. For quarians, you need to multiply x. You need to find again x minus average, y minus is corresponding to 1 minus average. Okay. Plus for the second point, it's going to be 2 minus 3 times 2 minus 206. Okay. Divided by 4. It gives us the variance of x. So, now I have variance of x, variance of y. So, then I can just divide this by this, right, according to get the beta. Now, beta is depends on, sorry, alpha depends on beta. Then I can get there. Okay. So, what I have here, I got the optimal, how for an optimal beta? Means that I got the optimal slope and optimal intersection. So, it shows that if your point is like this, the best function that you linear function that you can consider is going to be a function like this with a less than 1 intersection. This slope is almost 0.5. Because this is for this one, this is 0, like this. This is 0.5. Just a formulation. We call this as an ordinary basis. What you need to know is you need to know this. And how we get that one, you get based on solving this, that I showed on the slide. Any question on this? So, this is a simple linear regression. This is one way we have, what is the variance of x? Okay, intuitively. So, points, what is the variance of x? What does it show? It shows that how much of the points are difference from the average. Like, if you have like a, you want to find the variance for this class, suppose that everyone has one score. Okay, one score. And then you want to know what is the variance. What is the average? And then what's the score of each person from the average? Find that and take the mean of that one, right? Yeah, square and then take the mean of that. It shows that on average, what is the difference of each person from representative of that, let's say, population, okay? The same. We want to know that what is the variance of ages. So, then if you know that what is the average of age for each person, you can understand what is the difference from the average, okay? You do the same thing for all the samples. And then take that, take that and learn the family. That's what we see here. Like variance of x means that difference of each point from the average. Difference of each point from the average, right? There's sum of and divided by number of points that you have. That five points, major lead or variance, we say five minus. Let's have it. Okay. So, we're going to continue on age 20. Me too. Long time ago you said, when did you start your undergrad? I'm the greatest at it. Sorry, sorry, why aim, multiply? At first, I thought aim, multiply this one. Mm-hmm. But no, no, this, no, no. Oh, I thought there was something like this, right? And then it's kind of like, that's the feeling of the universe, right? Just a piece of x has to be equal to f or x to be equal to minus one. Because you have to look at the universe, right? You're a host, and you're looking at the whole x. But even if I'm x, even if I'm ordinary x, it's actually looking at x as a whole. It's just x is the universe. It's just one. If it's 2x, if you look at 2x as a whole, don't you want to say this whole thing? It's not me. I have a question for you. I thought it was equal to f or x to be equal to minus one. I thought it was equal, but why is there such an action? Of course there is. You can't ignore this. You ignore this. It's not scientific. That's my fx. It's my fx equal to 2x. If I ignore this, I look at this as a whole. According to your statement, I just become 1 times minus 1. Then it becomes 0. This is 1. 2 is gone. Do you understand? You look at this as a whole. Oh, wait a minute. fx is fake, right? Yes. Then I assume this 2x is equal to gx. If you say my fx is equal to gx, this is 1 times 1, right? 1 times 1. If according to your statement, I just want 1 times 1 minus 1 becomes 1, right? Then you don't deal with this. You don't deal with this. You can't do this. Right? Then it becomes 0. Then it becomes 0. Oh, x is gone. That's not right. This is according to your example. gx is equal to 2x. 1 is equal to 1, right? Is it right? 1. 1 is equal to 1. Then if you ask this gx to be equal to 1 times 1, you assume that it is equal to 1 times 1 times 2x. 0 times 1, right? Yes, that's 1. So 1 times 1 is equal to 1. 0 times 1 is equal to 1, right? Then it becomes 1. 2 is not like this. Then this is not scientific. Then if it is like this, it should be, according to your statement, it should be... You can't ignore the curve inside. gx is equal to 2x. It should be gx, right? Equal to 1. You just... There's another curve in 2x. It becomes 2. Isn't there one missing here? 1 times 2x is 1. 1 is equal to 1 times 2x. Actually, it should be 2, right? Yes. It should be correct. But if it is according to my error... Just a little. So if it is more than gx, it is equal to 2, right? It is more than 2. If it is 2, it becomes 1. If it is 2, it becomes 2. Oh, that's right. You just need to miss one. Yes, yes, that's right. You can't ignore it. Otherwise, we will do the opposite. If you ignore it, what will happen? If you ignore it, it will be wrong, right? But if we don't ignore it, you can't ignore it. Then I beg you. Then I can see all the things as a whole. This is a beg. And then keep the original. Do you think it's possible? Right? If it is like this, I can... If it is a long time ago, I will... I have seen a whole on this long time. Just because it is a long time ago, and most of the time you see it as a whole, you can see it as one here, right? But if you see it as one, it will be zero here. So if you beg like this, it doesn't make sense. It will destroy the original mathematical principle. Because I can see everything as a whole. If it is like this, it will only be one time. Then you beg once, and it becomes one time. All the beg will become one. This will destroy the mathematical principle. Anyway, you see what I'm talking about. So it's impossible. It's the number of the number of the number of the number of the number of the number of the number. No problem. Because you are separated. Oh, yes. But if I say it in a way, I see it as a whole. Then it becomes one. Right? This is the whole thing. I move it all over here. This is the whole thing. Oh, yes. And then one minus one becomes one. So it becomes this. It's not this. So it still needs to be in a single line. In this circle. Yes, yes. Because we build a mathematical principle. We don't need the mathematical principle. We need the mathematical principle. No mobile phone. No mobile phone.